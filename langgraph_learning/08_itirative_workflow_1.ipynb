{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "## Social Media Post generator",
   "id": "812031ec4a748b5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.764993Z",
     "start_time": "2025-09-29T00:21:25.761489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph,START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import operator"
   ],
   "id": "c40211cdb6f05c43",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.776024Z",
     "start_time": "2025-09-29T00:21:25.772669Z"
    }
   },
   "cell_type": "code",
   "source": "load_dotenv()",
   "id": "fcb3d1dc3ff8a7a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.783447Z",
     "start_time": "2025-09-29T00:21:25.781083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Select models based on their strengths for the task\n",
    "generator_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "evaluator_llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "optimizer_llm = ChatOpenAI(model='gpt-4o-mini')"
   ],
   "id": "c58c405258d3aec",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.790415Z",
     "start_time": "2025-09-29T00:21:25.788074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create Schema for the feedback evaluation\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"] = Field(..., description=\"Final evaluation result.\")\n",
    "    feedback: str = Field(..., description=\"feedback for the tweet.\")"
   ],
   "id": "1c49ac086cac983d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.794825Z",
     "start_time": "2025-09-29T00:21:25.793014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use the schema to create the evaluator with structured output\n",
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ],
   "id": "66fcb0457a78e605",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-29T00:21:25.798894Z",
     "start_time": "2025-09-29T00:21:25.797030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define state, add fields to avoid too many iterations and preserve the history of feedback and improvements made.\n",
    "class PostState(TypedDict):\n",
    "\n",
    "    topic: str\n",
    "    post: str\n",
    "    evaluation: Literal[\"approved\", \"needs_improvement\"]\n",
    "    feedback: str\n",
    "    iteration: int\n",
    "    max_iteration: int\n",
    "\n",
    "    post_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ],
   "id": "cdbd82afb42d2c70",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
